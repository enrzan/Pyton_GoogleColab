{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPVZ3g2sxCAgBwIdpXxGUk6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"77Zvh6xzEA_e"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class SimpleTransformer(nn.Module):\n","    def __init__(self, vocab_size, d_model, nhead, num_layers):\n","        super(SimpleTransformer, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.transformer = nn.Transformer(d_model, nhead, num_layers)\n","        self.fc = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, src, tgt):\n","        src = self.embedding(src)\n","        tgt = self.embedding(tgt)\n","        output = self.transformer(src, tgt)\n","        output = self.fc(output)\n","        return output\n","\n","# Parâmetros do modelo\n","vocab_size = 10000\n","d_model = 512\n","nhead = 8\n","num_layers = 6\n","\n","# Instanciando o modelo\n","model = SimpleTransformer(vocab_size, d_model, nhead, num_layers)\n","\n","# Exemplo de entrada\n","src = torch.randint(0, vocab_size, (10, 32))  # (sequência, batch_size)\n","tgt = torch.randint(0, vocab_size, (20, 32))\n","\n","# Forward pass\n","output = model(src, tgt)"]}]}